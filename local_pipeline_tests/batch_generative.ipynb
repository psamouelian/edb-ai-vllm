{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5cffb88-53dc-4022-9137-b30765c511e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31749332-691e-4d58-9fb1-65447928fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utilities/curl_utilities.ipynb\n",
    "%run ../utilities/postgres_utilities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c191b1-0bae-463b-b66e-389164f2631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"GritLM/GritLM-7B\"\n",
    "number_data_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5678afb-24f0-4444-a022-57f0208b78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8297fb66-4e3d-49b4-a82c-164c09d43505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:06<00:00, 22.25s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# Load the tokenizer for your model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the padding_side parameter (can be 'left' or 'right')\n",
    "tokenizer.padding_side = 'left'  # This sets padding to the left side\n",
    "\n",
    "#Note that model will not load without reducing precision to float16\n",
    "pipe = pipeline(\"text-generation\", model=model_name, tokenizer=tokenizer, trust_remote_code=False, torch_dtype=torch.float16,\n",
    "               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879e991-774f-4e00-9b11-0a5f36d8536d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6039eddb-8331-46a5-bc28-90db1ab403ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"select description from film limit {number_data_rows}\"\n",
    "film_descriptions = execute_sql_results(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24dc86-fc56-4d4e-b086-ddc670cf8a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc0cce2-8c93-4b9b-a19f-4a8d6c4fb05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch generative test using local model\n",
      "------------------------------------------------\n",
      "Texts generated ... 0 100 \n",
      "Time to generate text for 100 rows: 6.4079 seconds\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_description = \"Starting batch generative test using local model\"\n",
    "print(test_description)\n",
    "print(len(test_description) * \"-\") \n",
    "tic = time.perf_counter()\n",
    "print(\"Texts generated ...\", end=\" \")\n",
    "messages = list()\n",
    "for index, film in enumerate(film_descriptions):\n",
    "    description = film[0]\n",
    "    prompt = f\"Expand this movie description: {description}\"\n",
    "    messages.append([{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "start_offset = 0\n",
    "end_offset = batch_size\n",
    "question_response_pairs = list()\n",
    "while start_offset < number_data_rows:\n",
    "    print(start_offset, end_offset, end=\" \")\n",
    "    responses = pipe(messages[start_offset:end_offset], max_new_tokens=50)\n",
    "\n",
    "    for r in responses:\n",
    "        original_prompt = r[0]['generated_text'][0]['content']\n",
    "        generated_text = r[0]['generated_text'][1]['content']\n",
    "        assert len(generated_text) > 0\n",
    "        question_response_pairs.append(f\"{original_prompt}:{generated_text}\")\n",
    "\n",
    "    start_offset = end_offset\n",
    "    end_offset = end_offset + batch_size\n",
    "    if end_offset > number_data_rows:\n",
    "        end_offset = number_data_rows\n",
    "\n",
    "assert len(question_response_pairs) == number_data_rows\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(\"\")\n",
    "print(f\"Time to generate text for {number_data_rows} rows: {toc - tic:0.4f} seconds\")\n",
    "print(len(test_description) * \"-\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a066f04-9820-4c5b-bda6-56888747e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656ddd5-9c1e-46fe-bff1-ffa7f329e76c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
