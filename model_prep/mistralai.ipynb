{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724ae535-b029-414a-924b-8ad09f7df73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "from pathlib import Path\n",
    "from huggingface_hub import login\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9987dcb-b582-492e-8331-4e5ad312facc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98987dd-e5b1-4302-9689-095970834c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "login_token = os.environ.get('huggingface_token')\n",
    "login(token=login_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64d8e7b-0776-475c-9415-c36d61db2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup variables for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df4bf28-4764-4c64-8ed3-c1491e5e1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_models_path = './models'\n",
    "model_prefix = \"llama\"\n",
    "model_name = \"Mistral-7B-Instruct-v0.3\"\n",
    "full_model_name = f\"{model_prefix}/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a182279-f5af-4dd2-94da-cf51d0e32df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c50eae-2c6a-43fd-9b8a-752774307a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fd8e0f-3ded-43ab-8c0c-f2e3f02247ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(full_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784180aa-0b03-4489-b3eb-05c221d65256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a12e4d6fe7d41838e7def601bec3677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=full_model_name,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4f3807-6b87-4989-8d80-dc1b2123c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a quick inference test on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd79711-1261-4e53-bc96-49351d2343cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \" Arr matey! I be the digital parrot, ye scurvy dog! I'll be spinnin' ye yarns and crackin' ye jokes in me hearty pirate tongue. Now, what be ye seekin', landlubber?\\n\\nYe can call me Cap'n Parrot, or just Parrot if ye prefer. Now, what's the news from the seven seas? Or perhaps ye be lookin' for a good tale to tell at the tavern? I'll be happy to oblige!\"}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73819ddb-758c-447a-bbff-062c573446cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b90a80-5a46-4dc2-8bff-b4cb058cbc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model and its tokenizer to a local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd93b4e0-96c2-4a92-869f-7d1db6a04061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t\t\t  model.safetensors.index.json\n",
      "generation_config.json\t\t  special_tokens_map.json\n",
      "model-00001-of-00003.safetensors  tokenizer_config.json\n",
      "model-00002-of-00003.safetensors  tokenizer.json\n",
      "model-00003-of-00003.safetensors  tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "save_path = Path.home().joinpath(root_models_path, model_name)\n",
    "!mkdir -p {save_path}\n",
    "pipeline.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "!ls {save_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "491cad34-4900-4505-8776-80cdbaf10f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the s3 connection parameters (these are entered in the workbench setup screens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f37ef171-1870-42ee-823e-658a3a54ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b70f71-b948-4ead-8c80-5bfd6676c7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d05b31cc-a3e8-499d-9161-9266f4b498e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(\n",
    "            aws_access_key_id=aws_access_key_id,\n",
    "            aws_secret_access_key=aws_secret_access_key\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1cc7ae9-07b0-403e-a9d9-7444c4707081",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = session.resource(\n",
    "               's3',\n",
    "               config=botocore.client.Config(signature_version='s3v4'),\n",
    "               endpoint_url=endpoint_url,\n",
    "               region_name=region_name\n",
    "              )\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "                        \n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "                                \n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ce2dd-f335-4ed2-b9d7-d879acb747f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ad5eae7-d994-43d6-a6de-698952a2a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the model to an S3 bucket within the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e880593a-ae47-4ed1-b399-4185fb05b5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistralai/Mistral-7B-Instruct-v0.3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4f7204-a725-45a3-8308-bba6b0787413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/model-00003-of-00003.safetensors -> Mistral-7B-Instruct-v0.3/model-00003-of-00003.safetensors\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/model.safetensors.index.json -> Mistral-7B-Instruct-v0.3/model.safetensors.index.json\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/tokenizer_config.json -> Mistral-7B-Instruct-v0.3/tokenizer_config.json\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/special_tokens_map.json -> Mistral-7B-Instruct-v0.3/special_tokens_map.json\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/tokenizer.model -> Mistral-7B-Instruct-v0.3/tokenizer.model\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/tokenizer.json -> Mistral-7B-Instruct-v0.3/tokenizer.json\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/model-00001-of-00003.safetensors -> Mistral-7B-Instruct-v0.3/model-00001-of-00003.safetensors\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/generation_config.json -> Mistral-7B-Instruct-v0.3/generation_config.json\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/config.json -> Mistral-7B-Instruct-v0.3/config.json\n",
      "/opt/app-root/src/models/Mistral-7B-Instruct-v0.3/model-00002-of-00003.safetensors -> Mistral-7B-Instruct-v0.3/model-00002-of-00003.safetensors\n"
     ]
    }
   ],
   "source": [
    "upload_directory_to_s3(save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcfc8c-3fb6-4201-b201-fd90c36c19eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
