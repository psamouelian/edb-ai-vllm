{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724ae535-b029-414a-924b-8ad09f7df73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98987dd-e5b1-4302-9689-095970834c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64d8e7b-0776-475c-9415-c36d61db2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup variables for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df4bf28-4764-4c64-8ed3-c1491e5e1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_models_path = './models'\n",
    "model_prefix = \"ibm-granite\"\n",
    "model_name = \"granite-3.1-8b-instruct\"\n",
    "full_model_name = f\"{model_prefix}/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a182279-f5af-4dd2-94da-cf51d0e32df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c50eae-2c6a-43fd-9b8a-752774307a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5816c4cf-ca43-4534-9c94-f034ec38ab39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b64115cac1448484268ad35119a4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e10a6445415422aa235de528713ce94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:  83%|########3 | 4.14G/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221868d22920408c8d3161e4500a6295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.41G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b000c6533fb41f2b88ec7928427ba76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6a65b5b1174f46ae190761bc7e15bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(full_model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(full_model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(full_model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73819ddb-758c-447a-bbff-062c573446cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7b2e2-ae0b-47dc-ae63-a65f23388714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a quick inference test on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0d7355-12b9-49fe-8b39-8da57d21c987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current estimate for the age of the universe, based on data from the Planck satellite and other observations, is approximately 13.8 billion years. This value is derived from measurements of the cosmic microwave background radiation, which is the afterglow of the Big Bang. The age of the universe is a crucial piece of information in our understanding of cosmology and the evolution of the cosmos.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"How old is the universe?\"}\n",
    "]\n",
    "input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "#outputs = model.generate(input_tensor.to(model.device), max_new_tokens=100)\n",
    "outputs = model.generate(input_tensor.to(model.device), max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a817c4b-a5d0-422f-ba3c-cad3f8365fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b90a80-5a46-4dc2-8bff-b4cb058cbc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model and its tokenizer to a local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd93b4e0-96c2-4a92-869f-7d1db6a04061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added_tokens.json\t\t  model-00004-of-00004.safetensors\n",
      "config.json\t\t\t  model.safetensors.index.json\n",
      "generation_config.json\t\t  special_tokens_map.json\n",
      "merges.txt\t\t\t  tokenizer_config.json\n",
      "model-00001-of-00004.safetensors  tokenizer.json\n",
      "model-00002-of-00004.safetensors  vocab.json\n",
      "model-00003-of-00004.safetensors\n"
     ]
    }
   ],
   "source": [
    "save_path = Path.home().joinpath(root_models_path, model_name)\n",
    "!mkdir -p {save_path}\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "!ls {save_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491cad34-4900-4505-8776-80cdbaf10f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the s3 connection parameters (these are entered in the workbench setup screens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37ef171-1870-42ee-823e-658a3a54ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b70f71-b948-4ead-8c80-5bfd6676c7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05b31cc-a3e8-499d-9161-9266f4b498e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(\n",
    "            aws_access_key_id=aws_access_key_id,\n",
    "            aws_secret_access_key=aws_secret_access_key\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1cc7ae9-07b0-403e-a9d9-7444c4707081",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = session.resource(\n",
    "               's3',\n",
    "               config=botocore.client.Config(signature_version='s3v4'),\n",
    "               endpoint_url=endpoint_url,\n",
    "               region_name=region_name\n",
    "              )\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "                        \n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "                                \n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ce2dd-f335-4ed2-b9d7-d879acb747f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad5eae7-d994-43d6-a6de-698952a2a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the model to an S3 bucket within the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e880593a-ae47-4ed1-b399-4185fb05b5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ibm-granite/granite-3.1-8b-instruct'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4f7204-a725-45a3-8308-bba6b0787413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/models/granite-3.1-8b-instruct/merges.txt -> granite-3.1-8b-instruct/merges.txt\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/model.safetensors.index.json -> granite-3.1-8b-instruct/model.safetensors.index.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/tokenizer_config.json -> granite-3.1-8b-instruct/tokenizer_config.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/model-00004-of-00004.safetensors -> granite-3.1-8b-instruct/model-00004-of-00004.safetensors\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/model-00002-of-00004.safetensors -> granite-3.1-8b-instruct/model-00002-of-00004.safetensors\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/special_tokens_map.json -> granite-3.1-8b-instruct/special_tokens_map.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/model-00003-of-00004.safetensors -> granite-3.1-8b-instruct/model-00003-of-00004.safetensors\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/tokenizer.json -> granite-3.1-8b-instruct/tokenizer.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/generation_config.json -> granite-3.1-8b-instruct/generation_config.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/vocab.json -> granite-3.1-8b-instruct/vocab.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/added_tokens.json -> granite-3.1-8b-instruct/added_tokens.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/config.json -> granite-3.1-8b-instruct/config.json\n",
      "/opt/app-root/src/models/granite-3.1-8b-instruct/model-00001-of-00004.safetensors -> granite-3.1-8b-instruct/model-00001-of-00004.safetensors\n"
     ]
    }
   ],
   "source": [
    "upload_directory_to_s3(save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcfc8c-3fb6-4201-b201-fd90c36c19eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
